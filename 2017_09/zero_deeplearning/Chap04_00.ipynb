{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 二乗和誤差\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5*np.sum(np.square(y-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 交差エントロピー誤差\n",
    "def cross_entropy_error(y,t,eps=1e-7):\n",
    "    return -np.sum(t*np.log(y+eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# datasetを読み込む\n",
    "t_temp = dataset[[0]].values.ravel().astype(np.uint8)\n",
    "x_dataset = dataset.iloc[:,1:].values.astype(np.uint8)\n",
    "n_dataset = len(t_temp)\n",
    "t_dataset = np.zeros((n_dataset,10),np.uint8)\n",
    "t_dataset[np.arange(n_dataset),t_temp]=1 # 1-hot 表現にする\n",
    "\n",
    "# ランダムシャッフルする\n",
    "index = np.arange(n_dataset)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "x_dataset = x_dataset[index]\n",
    "t_dataset = t_dataset[index]\n",
    "\n",
    "# 教師データとテストデータに分割\n",
    "n_test = n_dataset / 4\n",
    "n_train = n_dataset - n_test \n",
    "x_train , t_train, x_test, t_test = \\\n",
    "    x_dataset[:n_train],t_dataset[:n_train],x_dataset[n_train:],t_dataset[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error2(y,t,eps=1e-7):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y+eps))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_diff(f,x,eps=1e-8):\n",
    "    return (f(x+eps)-f(x-eps))/(2*eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return 0.01*x**2+0.1*x\n",
    "\n",
    "def f_diff(x):\n",
    "    return 0.02*x+0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.99999999,  1.99999999])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerical_gradient(f,x,eps=1e-8):\n",
    "    f0 = f(x)\n",
    "    grad = np.zeros_like(x)\n",
    "    #print x\n",
    "    for i in range(len(x)):\n",
    "        x[i]+=eps\n",
    "        f1 = f(x)\n",
    "        x[i]-=eps\n",
    "        grad[i] = (f1-f0)/eps\n",
    "    \n",
    "    return grad\n",
    "\n",
    "numerical_gradient(lambda x:x[0]**2+x[1]**2,[1.0,1.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -4.77083345e-09  -4.77083345e-09]\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(f,init_x,lr=0.01,step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -= lr * grad\n",
    "    \n",
    "    return x\n",
    "\n",
    "f = lambda x:x[0]**2+x[1]**2\n",
    "print(gradient_descent(f,[1,1],lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30060961  0.33222499  0.3671654 ]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\" common/functions.py  \"\"\"\n",
    "    \n",
    "    \n",
    "    # mnistとかやる場合は2次元配列(データ数x入力次元)\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x,axis=0)\n",
    "        exp_x = np.exp(x)\n",
    "        y = exp_x / np.sum(exp_x,axis=0)\n",
    "        return y.T\n",
    "    \n",
    "    x = x - np.max(x)\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "# print( softmax(np.array([0.0,0.1,0.2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.420680743952367"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y,t,eps=1e-8):\n",
    "    \"\"\" common/functions.py  \"\"\"\n",
    "    \n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "    \n",
    "    # one-hot-vectorから正解ラベルのインデックスに\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "    batch_size = y.shape[0]\n",
    "    # print y\n",
    "    # print y[np.arange(batch_size),t]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]+eps))/batch_size\n",
    "\n",
    "cross_entropy_error(np.array([[0.2,0.1,0]]),np.array([[0,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.99999999,  1.99999999])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerical_gradient(f,x,eps=1e-8):\n",
    "    \"\"\" common/gradient.py \"\"\"\n",
    "    f0 = f(x)\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    # http://www.aipacommander.com/entry/2017/05/14/172220    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        i = it.multi_index\n",
    "        \n",
    "        x[i]+=eps\n",
    "        f1 = f(x)\n",
    "        x[i]-=eps\n",
    "        grad[i] = (f1-f0)/eps\n",
    "        \n",
    "        it.iternext()\n",
    "    \n",
    "    return grad\n",
    "\n",
    "numerical_gradient(lambda x:x[0]**2+x[1]**2,np.array([1.0,1.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58996193 -1.86691623  0.55723567]\n",
      " [-0.79245384 -0.84064432 -1.51343385]]\n",
      "[-0.3592313  -1.87672963 -1.02774906]\n",
      "0\n",
      "1.21763709478\n"
     ]
    }
   ],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # ガウス分布で初期化\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return np.dot(x,self.W)\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y,t)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "net = simpleNet()\n",
    "x = np.array([0.6,0.9])\n",
    "p = net.predict(x)\n",
    "t = np.array([0,0,1])\n",
    "\n",
    "print(net.W)\n",
    "print(p)\n",
    "print(np.argmax(p))\n",
    "print(net.loss(x,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34647487  0.07596797 -0.42244284]\n",
      " [ 0.51971227  0.11395196 -0.63366423]]\n"
     ]
    }
   ],
   "source": [
    "f = lambda W: net.loss(x,t)\n",
    "dW = numerical_gradient(f,net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
